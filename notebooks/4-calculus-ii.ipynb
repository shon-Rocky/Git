{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4-calculus-ii.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEsnrw0sDoeJ"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jonkrohn/ML-foundations/blob/master/notebooks/4-calculus-ii.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTOLgsbN69-P"
      },
      "source": [
        "# Calculus II: Partial Derivatives & Integrals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqUB9FTRAxd-"
      },
      "source": [
        "This class, *Calculus II: Partial Derivatives & Integrals*, builds on single-variable derivative calculus to introduce gradients and integral calculus. Gradients of learning, which are facilitated by partial-derivative calculus, are the basis of training most machine learning algorithms with data -- i.e., stochastic gradient descent (SGD). Paired with the principle of the chain rule (also covered in this class), SGD enables the backpropagation algorithm to train deep neural networks.\n",
        "\n",
        "Integral calculus, meanwhile, comes in handy for myriad tasks associated with machine learning, such as finding the area under the so-called “ROC curve” -- a prevailing metric for evaluating classification models. The content covered in this class is itself foundational for several other classes in the *Machine Learning Foundations* series, especially *Probability & Information Theory* and *Optimization*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4tBvI88BheF"
      },
      "source": [
        "Over the course of studying this topic, you'll:\n",
        "\n",
        "* Develop an understanding of what’s going on beneath the hood of machine learning algorithms, including those used for deep learning.\n",
        "* Be able to grasp the details of the partial-derivative, multivariate calculus that is common in machine learning papers as well as many in other subjects that underlie ML, including information theory and optimization algorithms.\n",
        "* Use integral calculus to determine the area under any given curve, a recurring task in ML applied, for example, to evaluate model performance by calculating the ROC AUC metric."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z68nQ0ekCYhF"
      },
      "source": [
        "**Note that this Jupyter notebook is not intended to stand alone. It is the companion code to a lecture or to videos from Jon Krohn's [Machine Learning Foundations](https://github.com/jonkrohn/ML-foundations) series, which offer detail on the following:**\n",
        "\n",
        "*Segment 1: Review of Introductory Calculus*\n",
        "\n",
        "* The Delta Method\n",
        "* Differentiation with Rules\n",
        "* AutoDiff: Automatic Differentiation\n",
        "\n",
        "\n",
        "*Segment 2: Machine Learning Gradients*\n",
        "\n",
        "* Partial Derivatives of Multivariate Functions\n",
        "* The Partial-Derivative Chain Rule\n",
        "* Quadratic Cost\n",
        "* Gradients\n",
        "* Gradient Descent\n",
        "* Backpropagation\n",
        "* Higher-Order Partial Derivatives\n",
        "\n",
        "\n",
        "*Segment 3: Integrals*\n",
        "\n",
        "* Binary Classification\n",
        "* The Confusion Matrix\n",
        "* The Receiver-Operating Characteristic (ROC) Curve\n",
        "* Calculating Integrals Manually\n",
        "* Numeric Integration with Python\n",
        "* Finding the Area Under the ROC Curve\n",
        "* Resources for Further Study of Calculus\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMomz4o6DoeT"
      },
      "source": [
        "## Segment 1: Review of Introductory Calculus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeOe0DrkDoeT"
      },
      "source": [
        "Refer to slides and [*Regression in PyTorch* notebook](https://github.com/jonkrohn/ML-foundations/blob/master/notebooks/regression-in-pytorch.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9v7wHzEaDoeT"
      },
      "source": [
        "## Segment 2: Gradients Applied to Machine Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-09IzaDRDoeU"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import math # for constant pi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmonXg8-DoeV"
      },
      "source": [
        "### Partial Derivatives of Multivariate Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jt2Fb7bmDoeV"
      },
      "source": [
        "Define a function $f(x, y)$ for $z = x^2 - y^2$:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xb_f6pUYDoeV"
      },
      "source": [
        "def f(my_x, my_y):\n",
        "    return my_x**2 - my_y**2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Yxx42_UDoeV"
      },
      "source": [
        "Plot $z$ with respect to $x$ by varying $x$..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Toba6LVQDoeW"
      },
      "source": [
        "xs = np.linspace(-3, 3, 1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sazf_xu9DoeW"
      },
      "source": [
        "...while holding $y$ constant (e.g., at $y = 0$):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Z31rNZvDoeW"
      },
      "source": [
        "zs_wrt_x = f(xs, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdZ6Rdr4DoeX"
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "plt.axvline(x=0, color='lightgray')\n",
        "plt.axhline(y=0, color='lightgray')\n",
        "\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('z', rotation=0)\n",
        "_ = ax.plot(xs, zs_wrt_x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TctSbA-VDoeY"
      },
      "source": [
        "To determine the slope of $z$ w.r.t. $x$ at a given point along the curve, we can use the partial derivative from the slides: $$ \\frac{\\partial z}{\\partial x} = 2x$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WM2UTR4DDoeY"
      },
      "source": [
        "def delz_delx(my_x, my_y): # y isn't relevant for *this* partial derivative; it often would be\n",
        "    return 2*my_x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqarAEMODoeY"
      },
      "source": [
        "x_samples = [-2, -1, 0, 1, 2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExzFLbjODoeY"
      },
      "source": [
        "colors = ['red', 'orange', 'green', 'blue', 'purple']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPeZ7Qf0DoeZ"
      },
      "source": [
        "def point_and_tangent_wrt_x(my_xs, my_x, my_y, my_f, fprime, col):\n",
        "\n",
        "    my_z = my_f(my_x, my_y) # z = f(x, y)\n",
        "    plt.scatter(my_x, my_z, c=col, zorder=3)\n",
        "\n",
        "    tangent_m = fprime(my_x, my_y) # Slope is partial derivative of f(x, y) w.r.t. x\n",
        "    tangent_b = my_z - tangent_m*my_x # Line is z=mx+b, so b=z-mx\n",
        "    tangent_line = tangent_m*my_xs + tangent_b\n",
        "\n",
        "    plt.plot(my_xs, tangent_line, c=col,\n",
        "             linestyle='dashed', linewidth=0.7, zorder=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3O2HIInDoeZ"
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "plt.axvline(x=0, color='lightgray')\n",
        "plt.axhline(y=0, color='lightgray')\n",
        "\n",
        "for i, x in enumerate(x_samples):\n",
        "    point_and_tangent_wrt_x(xs, x, 0, f, delz_delx, colors[i])\n",
        "\n",
        "plt.ylim(-1, 9)\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('z', rotation=0)\n",
        "_ = ax.plot(xs, zs_wrt_x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8IJZYZfDoeZ"
      },
      "source": [
        "Thereby visually demonstrating $\\frac{\\partial z}{\\partial x} = 2x$.\n",
        "\n",
        "That is, the slope of $z$ along the $x$ axis is *twice* the $x$ value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Vxr1W0IDoea"
      },
      "source": [
        "**Return to slides here.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEVnit5gDoea"
      },
      "source": [
        "Now let's plot $z$ with respect to $y$ by varying $y$..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZF8285-Doea"
      },
      "source": [
        "ys = np.linspace(-3, 3, 1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSzx8uhLDoea"
      },
      "source": [
        "...while holding $x$ constant (e.g., at $x$ = 0):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7L4yZ1aDoeb"
      },
      "source": [
        "zs_wrt_y = f(0, ys)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGNORzJCDoeb"
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "plt.axvline(x=0, color='lightgray')\n",
        "plt.axhline(y=0, color='lightgray')\n",
        "\n",
        "plt.xlabel('y')\n",
        "plt.ylabel('z', rotation=0)\n",
        "_ = ax.plot(ys, zs_wrt_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yftPl60zDoeb"
      },
      "source": [
        "As in the slides, the partial derivative of $z$ w.r.t $y$ happens to be independent of $x$ (just as we observed $x$ is independent of $y$ above), so while $z$ varies as a function of both $x$ and $y$, the slope of $z$ w.r.t $y$ is the same no matter what $x$ is: $$ \\frac{\\partial z}{\\partial y} = -2y $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xX3gAdyWDoec"
      },
      "source": [
        "So for example, holding $x$ constant at 2 instead of 0 increases $z$, but has no impact whatsoever on the slope of $z$ w.r.t. $y$:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdaSBdlrDoec"
      },
      "source": [
        "zs_wrt_y = f(2, ys)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PW49KD7Doec"
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "plt.axvline(x=0, color='lightgray')\n",
        "plt.axhline(y=0, color='lightgray')\n",
        "\n",
        "plt.xlabel('y')\n",
        "plt.ylabel('z', rotation=0)\n",
        "_ = ax.plot(ys, zs_wrt_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vMax3uODoec"
      },
      "source": [
        "def delz_dely(my_x, my_y):\n",
        "    return -2*my_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkQ4GQyBDoed"
      },
      "source": [
        "y_samples = [-2, -1, 0, 1, 2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxsR448zDoed"
      },
      "source": [
        "def point_and_tangent_wrt_y(my_ys, my_x, my_y, my_f, fprime, col): # changed my_xs to my_ys\n",
        "\n",
        "    my_z = my_f(my_x, my_y)\n",
        "    plt.scatter(my_y, my_z, c=col, zorder=3) # changed my_x to my_y\n",
        "\n",
        "    tangent_m = fprime(my_x, my_y)\n",
        "    tangent_b = my_z - tangent_m*my_y # changed my_x to my_y\n",
        "    tangent_line = tangent_m*my_ys + tangent_b # changed my_xs to my_ys\n",
        "\n",
        "    plt.plot(my_ys, tangent_line, c=col,\n",
        "             linestyle='dashed', linewidth=0.7, zorder=3) # changed my_xs to my_ys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8EXlci4Doed"
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "plt.axvline(x=0, color='lightgray')\n",
        "plt.axhline(y=0, color='lightgray')\n",
        "\n",
        "for i, y in enumerate(y_samples):\n",
        "    point_and_tangent_wrt_y(ys, 2, y, f, delz_dely, colors[i])\n",
        "\n",
        "plt.ylim(-5, 5)\n",
        "plt.xlabel('y')\n",
        "plt.ylabel('z', rotation=0)\n",
        "_ = ax.plot(xs, zs_wrt_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZV2FTIU66UG-"
      },
      "source": [
        "Thereby visually demonstrating $\\frac{\\partial z}{\\partial y} = -2y$.\n",
        "\n",
        "That is, the slope of $z$ along the $y$ axis is *twice* the $y$ value *and inverted*, resulting in the parabolic curve opening downward."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7P12cWuDoef"
      },
      "source": [
        "**Exercises**: Use pencil and paper to determine:\n",
        "\n",
        "* The value of $z$,\n",
        "* The slope of $z$ with respect to $x$,\n",
        "* And the slope of $z$ with respect to $y$\n",
        "\n",
        "...at the points where:\n",
        "\n",
        "1. $x = 3, y = 0$\n",
        "2. $x = 2, y = 3$\n",
        "3. $x = -2, y = -3$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwiI0uisDoeg"
      },
      "source": [
        "Determining partial derivatives by hand using rules is helpful for understanding how calculus works. In practice, however, autodiff enables us to do so more easily (especially if there are a large number of variables). For example, let's use the PyTorch automatic differentiation library to calculate the slope of $z$ with respect to both $x$ and $y$ at any given point $(x, y, z)$:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHeFsRfrDoeg"
      },
      "source": [
        "x = torch.tensor(0.).requires_grad_()\n",
        "x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzWjTchwDoeg"
      },
      "source": [
        "y = torch.tensor(0.).requires_grad_()\n",
        "y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7TprOE-Doeh"
      },
      "source": [
        "z = f(x, y) # Forward pass\n",
        "z"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyefZb67Doeh"
      },
      "source": [
        "z.backward() # Autodiff"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_L7fUeBfDoeh"
      },
      "source": [
        "As we already knew from our exercises above, the slope of the point (0, 0, 0) is zero with respect to both the $x$ and $y$ axes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCX2ngT9Doeh"
      },
      "source": [
        "x.grad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DeU2IYODoei"
      },
      "source": [
        "y.grad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eblx3YW6Doei"
      },
      "source": [
        "**Exercise**: Repeat the most recent pencil-and-paper exercises using PyTorch (or TensorFlow, if you prefer)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPxR9412Doei"
      },
      "source": [
        "**Return to slides here.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NqDfYGeDoej"
      },
      "source": [
        "### Partial Derivatives of a Cylinder's Volume"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zOAmeOnDoej"
      },
      "source": [
        "The volume of a cylinder is described by $v = \\pi r^2 l$ where:\n",
        "\n",
        "* $r$ is the radius of the cylinder\n",
        "* $l$ is its length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y345YQ2iDoej"
      },
      "source": [
        "def cylinder_vol(my_r, my_l):\n",
        "    return math.pi * my_r**2 * my_l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eGolCTLDoej"
      },
      "source": [
        "# Let's say the radius is 3 meters...\n",
        "r = torch.tensor(3.).requires_grad_()\n",
        "r"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sp3kUgQ6Doej"
      },
      "source": [
        "# ...and length is 5 meters:\n",
        "l = torch.tensor(5.).requires_grad_()\n",
        "l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FBBkAM6Doek"
      },
      "source": [
        "# Then the volume of the cylinder is 141.4 cubic meters:\n",
        "v = cylinder_vol(r, l)\n",
        "v"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iGlPQyjDoek"
      },
      "source": [
        "v.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvIA09YGDoek"
      },
      "source": [
        "l.grad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYD2k4J3Doel"
      },
      "source": [
        "As derived on the slides: $$\\frac{\\partial v}{\\partial l} = \\pi r^2$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6YRwpMvDoel"
      },
      "source": [
        "math.pi * 3**2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UavsjoQFDoel"
      },
      "source": [
        "This means that with $r = 3$, a change in $l$ by one unit corresponds to a change in $v$ of 28.27$\\text{m}^3$. We can prove this to ourselves:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H32PplygDoel"
      },
      "source": [
        "cylinder_vol(3, 6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmwxrip1Doem"
      },
      "source": [
        "cylinder_vol(3, 6) - cylinder_vol(3, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGuDzwwxDoem"
      },
      "source": [
        "cylinder_vol(3, 7) - cylinder_vol(3, 6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDJydipwDoel"
      },
      "source": [
        "**Return to slides here.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yC4GJ8iZDoem"
      },
      "source": [
        "For changes in $v$ with respect to $r$ we have the following from the slides: $$\\frac{\\partial v}{\\partial r} = 2 \\pi r l$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAVbIBiCDoen"
      },
      "source": [
        "r.grad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzHESN6XDoen"
      },
      "source": [
        "2 * math.pi * 3 * 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWzx4YxuDoen"
      },
      "source": [
        "$r$ is included in the partial derivative so adjusting it affects the scale of its impact on $v$. Although it's our first example in this notebook, it is typical in calculus for the derivative only to apply at an infinitesimally small $\\Delta r$. The smaller the $\\Delta r$, the closer to the true $\\frac{\\partial v}{\\partial r}$. E.g., at $\\Delta r = 1 \\times 10^{-6}$:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JN0waPUmDoen"
      },
      "source": [
        "delta = 1e-6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCk5RPL8Doeo"
      },
      "source": [
        "(cylinder_vol(3 + delta, 5) - cylinder_vol(3, 5)) / delta # Dividing by delta restores scale"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4U_lu-yDoeo"
      },
      "source": [
        "**Return to slides here.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CKfShVZDoeo"
      },
      "source": [
        "### Gradients of Cost w.r.t. Model Parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbAlp7N3Doeo"
      },
      "source": [
        "See the standalone notebooks:\n",
        "\n",
        "* [Single-Point Regression Gradient](https://github.com/jonkrohn/ML-foundations/blob/master/notebooks/single-point-regression-gradient.ipynb)\n",
        "* [Batch Regression Gradient](https://github.com/jonkrohn/ML-foundations/blob/master/notebooks/batch-regression-gradient.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GkxmPtUDoeo"
      },
      "source": [
        "## Segment 3: Integrals"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RNXGSU_Doep"
      },
      "source": [
        "from scipy.integrate import quad # \"quadrature\" = numerical integration (as opposed to symbolic)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gcCUd4QDoep"
      },
      "source": [
        "From the slides: $$ \\int_1^2 \\frac{x}{2} dx = \\frac{3}{4} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQSGdUlIDoep"
      },
      "source": [
        "def g(x):\n",
        "    return x/2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ifu7x0iRDoep"
      },
      "source": [
        "quad(g, 1, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfwAbtc5Doep"
      },
      "source": [
        "The second output of `quad` is an estimate of the absolute error of the integral, which in this case is essentially zero."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "By-nY8jBDoeq"
      },
      "source": [
        "**Return to the slides here.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXY-74QaDoeq"
      },
      "source": [
        "def h(x):\n",
        "    return 2*x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A26vlFzCDoeq"
      },
      "source": [
        "quad(h, 3, 4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Crw18QJv7oY3"
      },
      "source": [
        "**Return to the slides here.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAmdDoskDoeq"
      },
      "source": [
        "### Area Under the ROC Curve"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_wFvlHEDoeq"
      },
      "source": [
        "When we don't have a function but we do have $(x, y)$ coordinates, we can use the scikit-learn library's `auc()` method, which uses a numerical approach (the [trapezoidal rule](https://en.wikipedia.org/wiki/Trapezoidal_rule)) to find the area under the curve described by the coordinates:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_X0uiqKLDoeq"
      },
      "source": [
        "from sklearn.metrics import auc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XilqUs--Doer"
      },
      "source": [
        "From the slides, the $(x, y)$ coordinates of our hot dog-detecting ROC curve are:\n",
        "\n",
        "* (0, 0)\n",
        "* (0, 0.5)\n",
        "* (0.5, 0.5)\n",
        "* (0.5, 1)\n",
        "* (1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yu9wg0aoDoer"
      },
      "source": [
        "xs = [0, 0,   0.5, 0.5, 1]\n",
        "ys = [0, 0.5, 0.5, 1,   1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwnqDGueDoer"
      },
      "source": [
        "auc(xs, ys)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}